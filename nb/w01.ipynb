{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9756f9a2-af8f-4c25-be51-d24b2b6fd6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "Setup complete ✅ (24 CPUs, 47.0 GB RAM, 238.3/246.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO \n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "FREEZE = 10\n",
    "EPOCHS = 1\n",
    "CFG_PATH = \"../barcodes_mini.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c20bd4-b3c9-4c44-bf17-29a203cc8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../yolov8x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42af50bb-0b4e-4ee4-94a2-2b0e7fede214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freezing model.0.conv.weight\n",
      "freezing model.0.bn.weight\n",
      "freezing model.0.bn.bias\n",
      "freezing model.1.conv.weight\n",
      "freezing model.1.bn.weight\n",
      "freezing model.1.bn.bias\n",
      "freezing model.2.cv1.conv.weight\n",
      "freezing model.2.cv1.bn.weight\n",
      "freezing model.2.cv1.bn.bias\n",
      "freezing model.2.cv2.conv.weight\n",
      "freezing model.2.cv2.bn.weight\n",
      "freezing model.2.cv2.bn.bias\n",
      "freezing model.2.m.0.cv1.conv.weight\n",
      "freezing model.2.m.0.cv1.bn.weight\n",
      "freezing model.2.m.0.cv1.bn.bias\n",
      "freezing model.2.m.0.cv2.conv.weight\n",
      "freezing model.2.m.0.cv2.bn.weight\n",
      "freezing model.2.m.0.cv2.bn.bias\n",
      "freezing model.2.m.1.cv1.conv.weight\n",
      "freezing model.2.m.1.cv1.bn.weight\n",
      "freezing model.2.m.1.cv1.bn.bias\n",
      "freezing model.2.m.1.cv2.conv.weight\n",
      "freezing model.2.m.1.cv2.bn.weight\n",
      "freezing model.2.m.1.cv2.bn.bias\n",
      "freezing model.2.m.2.cv1.conv.weight\n",
      "freezing model.2.m.2.cv1.bn.weight\n",
      "freezing model.2.m.2.cv1.bn.bias\n",
      "freezing model.2.m.2.cv2.conv.weight\n",
      "freezing model.2.m.2.cv2.bn.weight\n",
      "freezing model.2.m.2.cv2.bn.bias\n",
      "freezing model.3.conv.weight\n",
      "freezing model.3.bn.weight\n",
      "freezing model.3.bn.bias\n",
      "freezing model.4.cv1.conv.weight\n",
      "freezing model.4.cv1.bn.weight\n",
      "freezing model.4.cv1.bn.bias\n",
      "freezing model.4.cv2.conv.weight\n",
      "freezing model.4.cv2.bn.weight\n",
      "freezing model.4.cv2.bn.bias\n",
      "freezing model.4.m.0.cv1.conv.weight\n",
      "freezing model.4.m.0.cv1.bn.weight\n",
      "freezing model.4.m.0.cv1.bn.bias\n",
      "freezing model.4.m.0.cv2.conv.weight\n",
      "freezing model.4.m.0.cv2.bn.weight\n",
      "freezing model.4.m.0.cv2.bn.bias\n",
      "freezing model.4.m.1.cv1.conv.weight\n",
      "freezing model.4.m.1.cv1.bn.weight\n",
      "freezing model.4.m.1.cv1.bn.bias\n",
      "freezing model.4.m.1.cv2.conv.weight\n",
      "freezing model.4.m.1.cv2.bn.weight\n",
      "freezing model.4.m.1.cv2.bn.bias\n",
      "freezing model.4.m.2.cv1.conv.weight\n",
      "freezing model.4.m.2.cv1.bn.weight\n",
      "freezing model.4.m.2.cv1.bn.bias\n",
      "freezing model.4.m.2.cv2.conv.weight\n",
      "freezing model.4.m.2.cv2.bn.weight\n",
      "freezing model.4.m.2.cv2.bn.bias\n",
      "freezing model.4.m.3.cv1.conv.weight\n",
      "freezing model.4.m.3.cv1.bn.weight\n",
      "freezing model.4.m.3.cv1.bn.bias\n",
      "freezing model.4.m.3.cv2.conv.weight\n",
      "freezing model.4.m.3.cv2.bn.weight\n",
      "freezing model.4.m.3.cv2.bn.bias\n",
      "freezing model.4.m.4.cv1.conv.weight\n",
      "freezing model.4.m.4.cv1.bn.weight\n",
      "freezing model.4.m.4.cv1.bn.bias\n",
      "freezing model.4.m.4.cv2.conv.weight\n",
      "freezing model.4.m.4.cv2.bn.weight\n",
      "freezing model.4.m.4.cv2.bn.bias\n",
      "freezing model.4.m.5.cv1.conv.weight\n",
      "freezing model.4.m.5.cv1.bn.weight\n",
      "freezing model.4.m.5.cv1.bn.bias\n",
      "freezing model.4.m.5.cv2.conv.weight\n",
      "freezing model.4.m.5.cv2.bn.weight\n",
      "freezing model.4.m.5.cv2.bn.bias\n",
      "freezing model.5.conv.weight\n",
      "freezing model.5.bn.weight\n",
      "freezing model.5.bn.bias\n",
      "freezing model.6.cv1.conv.weight\n",
      "freezing model.6.cv1.bn.weight\n",
      "freezing model.6.cv1.bn.bias\n",
      "freezing model.6.cv2.conv.weight\n",
      "freezing model.6.cv2.bn.weight\n",
      "freezing model.6.cv2.bn.bias\n",
      "freezing model.6.m.0.cv1.conv.weight\n",
      "freezing model.6.m.0.cv1.bn.weight\n",
      "freezing model.6.m.0.cv1.bn.bias\n",
      "freezing model.6.m.0.cv2.conv.weight\n",
      "freezing model.6.m.0.cv2.bn.weight\n",
      "freezing model.6.m.0.cv2.bn.bias\n",
      "freezing model.6.m.1.cv1.conv.weight\n",
      "freezing model.6.m.1.cv1.bn.weight\n",
      "freezing model.6.m.1.cv1.bn.bias\n",
      "freezing model.6.m.1.cv2.conv.weight\n",
      "freezing model.6.m.1.cv2.bn.weight\n",
      "freezing model.6.m.1.cv2.bn.bias\n",
      "freezing model.6.m.2.cv1.conv.weight\n",
      "freezing model.6.m.2.cv1.bn.weight\n",
      "freezing model.6.m.2.cv1.bn.bias\n",
      "freezing model.6.m.2.cv2.conv.weight\n",
      "freezing model.6.m.2.cv2.bn.weight\n",
      "freezing model.6.m.2.cv2.bn.bias\n",
      "freezing model.6.m.3.cv1.conv.weight\n",
      "freezing model.6.m.3.cv1.bn.weight\n",
      "freezing model.6.m.3.cv1.bn.bias\n",
      "freezing model.6.m.3.cv2.conv.weight\n",
      "freezing model.6.m.3.cv2.bn.weight\n",
      "freezing model.6.m.3.cv2.bn.bias\n",
      "freezing model.6.m.4.cv1.conv.weight\n",
      "freezing model.6.m.4.cv1.bn.weight\n",
      "freezing model.6.m.4.cv1.bn.bias\n",
      "freezing model.6.m.4.cv2.conv.weight\n",
      "freezing model.6.m.4.cv2.bn.weight\n",
      "freezing model.6.m.4.cv2.bn.bias\n",
      "freezing model.6.m.5.cv1.conv.weight\n",
      "freezing model.6.m.5.cv1.bn.weight\n",
      "freezing model.6.m.5.cv1.bn.bias\n",
      "freezing model.6.m.5.cv2.conv.weight\n",
      "freezing model.6.m.5.cv2.bn.weight\n",
      "freezing model.6.m.5.cv2.bn.bias\n",
      "freezing model.7.conv.weight\n",
      "freezing model.7.bn.weight\n",
      "freezing model.7.bn.bias\n",
      "freezing model.8.cv1.conv.weight\n",
      "freezing model.8.cv1.bn.weight\n",
      "freezing model.8.cv1.bn.bias\n",
      "freezing model.8.cv2.conv.weight\n",
      "freezing model.8.cv2.bn.weight\n",
      "freezing model.8.cv2.bn.bias\n",
      "freezing model.8.m.0.cv1.conv.weight\n",
      "freezing model.8.m.0.cv1.bn.weight\n",
      "freezing model.8.m.0.cv1.bn.bias\n",
      "freezing model.8.m.0.cv2.conv.weight\n",
      "freezing model.8.m.0.cv2.bn.weight\n",
      "freezing model.8.m.0.cv2.bn.bias\n",
      "freezing model.8.m.1.cv1.conv.weight\n",
      "freezing model.8.m.1.cv1.bn.weight\n",
      "freezing model.8.m.1.cv1.bn.bias\n",
      "freezing model.8.m.1.cv2.conv.weight\n",
      "freezing model.8.m.1.cv2.bn.weight\n",
      "freezing model.8.m.1.cv2.bn.bias\n",
      "freezing model.8.m.2.cv1.conv.weight\n",
      "freezing model.8.m.2.cv1.bn.weight\n",
      "freezing model.8.m.2.cv1.bn.bias\n",
      "freezing model.8.m.2.cv2.conv.weight\n",
      "freezing model.8.m.2.cv2.bn.weight\n",
      "freezing model.8.m.2.cv2.bn.bias\n",
      "freezing model.9.cv1.conv.weight\n",
      "freezing model.9.cv1.bn.weight\n",
      "freezing model.9.cv1.bn.bias\n",
      "freezing model.9.cv2.conv.weight\n",
      "freezing model.9.cv2.bn.weight\n",
      "freezing model.9.cv2.bn.bias\n"
     ]
    }
   ],
   "source": [
    "freeze = [f'model.{x}.' for x in range(FREEZE)]  # layers to freeze \n",
    "for k, v in model.model.named_parameters(): \n",
    "    v.requires_grad = True  # train all layers \n",
    "    if any(x in k for x in freeze): \n",
    "        print(f'freezing {k}') \n",
    "        v.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba526126-f71d-43c9-b43e-12d8be67b95c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=../yolov8x.pt, data=../barcodes_mini.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8718931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 640]]          \n",
      "Model summary: 365 layers, 68153571 parameters, 68153555 gradients\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=c88b2a691da44d6fba0d214a98b36ed3\n",
      "ClearML results page: https://app.clear.ml/projects/b0d06e368172415bb24bffdb7f1f6d04/experiments/c88b2a691da44d6fba0d214a98b36ed3/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/fatuus/data/goods-barcodes/mini_img... 6 images, 0 backgro\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/fatuus/data/goods-barcodes/mini_img.cache\n",
      "/home/fatuus/deepschool-cvr-bcdetect/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/fatuus/data/goods-barcodes/mini_img.cache... 6 images, 0 bac\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "2023-07-01 18:31:57,370 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1         0G      1.486      3.669      1.643         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          6          6    0.00222      0.667      0.014    0.00518\n",
      "\n",
      "1 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "Model summary (fused): 268 layers, 68124531 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          6          6    0.00222      0.667      0.014    0.00519\n",
      "Speed: 0.2ms preprocess, 189.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-01 18:32:44,292 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/w01.c88b2a691da44d6fba0d214a98b36ed3/models/best.pt\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "model.train(data=CFG_PATH, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d04615-ee61-4e8d-846b-1d46f9ab81c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "Model summary (fused): 268 layers, 68124531 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/fatuus/data/goods-barcodes/mini_img.cache... 6 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          6          6    0.00222      0.667      0.014    0.00519\n",
      "Speed: 0.2ms preprocess, 255.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/fatuus/deepschool-cvr-bcdetect/runs/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de739a1-84a8-4da0-80a8-ec01491a18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/fatuus/data/goods-barcodes/test_img... 53 images, 0 backgrou\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/fatuus/data/goods-barcodes/test_img.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         53         53    0.00397       0.83     0.0147    0.00666\n",
      "Speed: 0.2ms preprocess, 230.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/fatuus/deepschool-cvr-bcdetect/runs/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(\"../barcodes_test.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb1af15-a4a7-4058-bdb8-1e11ee2e9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.yolo.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7fe3ebe2ba00>\n",
      "fitness: 0.007459996678427732\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([  0.0066579])\n",
      "names: {0: 'barcode'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.003966632068820086, 'metrics/recall(B)': 0.8301886792452831, 'metrics/mAP50(B)': 0.014678446321224729, 'metrics/mAP50-95(B)': 0.006657946718116955, 'fitness': 0.007459996678427732}\n",
      "save_dir: PosixPath('/home/fatuus/deepschool-cvr-bcdetect/runs/detect/val4')\n",
      "speed: {'preprocess': 0.23746490478515625, 'inference': 230.0086111392615, 'loss': 0.00023392011534492926, 'postprocess': 3.3876176150339954}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1350f8-c820-48d4-a4a3-e10a433e7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 🚀 Python-3.8.16 torch-2.0.1+cu117 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (130.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"onnx>=1.12.0\" not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 72.1 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/fatuus/deepschool-cvr-bcdetect/venv/lib/python3.8/site-packages (from onnx>=1.12.0) (1.24.4)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.12.0)\n",
      "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.5/304.5 kB 399.7 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /home/fatuus/deepschool-cvr-bcdetect/venv/lib/python3.8/site-packages (from onnx>=1.12.0) (4.7.0)\n",
      "Installing collected packages: protobuf, onnx\n",
      "Successfully installed onnx-1.14.0 protobuf-4.23.3\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 13.9s, saved as /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.onnx (260.1 MB)\n",
      "\n",
      "Export complete (14.5s)\n",
      "Results saved to \u001b[1m/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=/home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.onnx imgsz=640 data=../barcodes_mini.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "path = model.export(format=\"onnx\")  # export the model to ONNX format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1594ae-9a94-47c0-97d6-38939598406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to exported weights: /home/fatuus/deepschool-cvr-bcdetect/runs/detect/train6/weights/best.onnx\n"
     ]
    }
   ],
   "source": [
    "print(f\"path to exported weights: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f79700-507c-432b-9dd9-32edbc92b53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
